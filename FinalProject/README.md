# 期末專案報告

## 摘要

本專案旨在使用 Hugging Face Transformers 函式庫，基於 DistilBERT 模型建構一個命名實體識別（NER）系統，並在 WikiANN 資料集（英文部分）上進行訓練與評估。專案採用 Python 實作，包含資料預處理、模型訓練與評估流程，最終在測試集上達到 **F1 分數 0.8151**、**精確率 0.8059**、**召回率 0.8244** 以及 **準確率 0.9199**。本報告詳細介紹專案背景、方法、實作細節、實驗結果與結論。

## 引言

命名實體識別（NER）是自然語言處理（NLP）中的核心任務，旨在從文本中識別並分類特定實體，例如人名、地名和組織名。本專案利用 **DistilBERT**（一種輕量化的 BERT）進行 NER 任務，並使用 **WikiANN 資料集** 進行 Fine-tune 與評估。

## 方法

### 資料集

本專案使用 **WikiANN 資料集**（英文部分），包含以下數據：
- **訓練集**：20,000 筆
- **驗證集**：10,000 筆
- **測試集**：10,000 筆

每個樣本包含詞彙序列及其對應的 NER 標籤，標籤包括：
- `O`（非實體）
- `B-PER`（人名開頭）、`I-PER`（人名內部）
- `B-ORG`（組織開頭）、`I-ORG`（組織內部）
- `B-LOC`（地名開頭）、`I-LOC`（地名內部）

---
### 模型架構

採用 Hugging Face 的 `distilbert-base-uncased` 模型，該模型為 6 層輕量化 Transformer 模型，相較標準 BERT 具有更低的計算需求。模型配置為 token 分類任務，輸出層對應 7 個 NER 標籤。

---
### 資料預處理

資料預處理步驟如下：
1. 使用 `AutoTokenizer` 將詞彙序列轉換為 token，進行填充（padding）與截斷（truncation）。
2. 對齊 NER 標籤與 token，將特殊 token 分配標籤 `-100`，以確保在損失計算中被忽略。
3. 使用 `DataCollatorForTokenClassification` 實現動態填充，提高訓練效率。

---
### 訓練設定

訓練採用以下超參數：
- **批次大小（Batch Size）**：64
- **訓練週期（Epochs）**：2
- **學習率**：預設值（5e-5，隨訓練線性衰減）
- **評估策略**：每 epoch 結束時進行驗證

使用 `Trainer` API 進行模型訓練，並以精確率（Precision）、召回率（Recall）、F1 分數與準確率（Accuracy）作為評估指標。

## 實作細節

### 程式碼結構

專案程式碼使用 Python 撰寫，依賴以下函式庫：
- `datasets`：載入與處理 WikiANN 資料集。
- `transformers`：提供 DistilBERT 模型與 tokenizer。
- `seqeval`：計算 NER 任務的評估指標。

程式碼包含以下主要模組：
1. **資料載入與預處理**：使用 `load_dataset` 載入資料集，定義 `tokenize_and_align_labels` 函數進行 tokenization 與標籤對齊。
2. **模型訓練**：使用 `TrainingArguments` 與 `Trainer` 配置訓練流程。
3. **評估**：定義 `compute_metrics` 函數計算精確率、召回率、F1 分數與準確率。

## 實驗結果

### 訓練與驗證結果

訓練過程歷經 2 個 epoch，結果如下：

- **第一 epoch**：
  - 訓練損失：0.4479
  - 驗證損失：0.2833
  - 驗證精確率：0.7824
  - 驗證召回率：0.8102
  - 驗證 F1 分數：0.7961
  - 驗證準確率：0.9118

- **第二 epoch**：
  - 訓練損失：0.2302
  - 驗證損失：0.2683
  - 驗證精確率：0.8009
  - 驗證召回率：0.8219
  - 驗證 F1 分數：0.8112
  - 驗證準確率：0.9182
 
經多次測試後發現模型 Fine-tune 大多收斂在第 2 個 Epoch，往後將出現 Overfitting 的情況

---
### 測試集結果

在測試集上的最終評估結果如下：

| 指標     | 精確率 | 召回率 | F1 分數 | 準確率 |
|----------|--------|--------|---------|--------|
| 測試集   | 0.8059 | 0.8244 | 0.8151  | 0.9199 |
